{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCC Python Implementation Profiling\n",
    "\n",
    "This notebook provides quantitative profiling evidence showing what percentage of CCC (Clustermatch Correlation Coefficient) runtime is attributable to ARI (Adjusted Rand Index) calculations.\n",
    "\n",
    "**Goal**: Address reviewer feedback requesting profiling data to support the claim that ARI computation represents the main computational bottleneck in CCC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "from pstats import SortKey\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the libs directory to the path\n",
    "sys.path.insert(0, os.path.abspath('../../libs'))\n",
    "\n",
    "from ccc.coef.impl import ccc\n",
    "from ccc.sklearn.metrics import adjusted_rand_index, get_pair_confusion_matrix, get_contingency_matrix\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_features: int, n_samples: int, seed: int = 42) -> np.ndarray:\n",
    "    \"\"\"Generate synthetic numerical data for benchmarking.\n",
    "    \n",
    "    Args:\n",
    "        n_features: Number of features (rows)\n",
    "        n_samples: Number of samples (columns)\n",
    "        seed: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        2D numpy array of shape (n_features, n_samples)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    return np.random.rand(n_features, n_samples)\n",
    "\n",
    "\n",
    "def profile_ccc(data: np.ndarray, n_jobs: int = 1) -> pstats.Stats:\n",
    "    \"\"\"Profile the CCC function and return stats.\n",
    "    \n",
    "    Args:\n",
    "        data: Input data array\n",
    "        n_jobs: Number of CPU cores to use\n",
    "    \n",
    "    Returns:\n",
    "        pstats.Stats object with profiling results\n",
    "    \"\"\"\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    \n",
    "    result = ccc(data, n_jobs=n_jobs)\n",
    "    \n",
    "    profiler.disable()\n",
    "    \n",
    "    # Create stats object\n",
    "    stats = pstats.Stats(profiler)\n",
    "    return stats, result\n",
    "\n",
    "\n",
    "def extract_function_times(stats: pstats.Stats) -> dict:\n",
    "    \"\"\"Extract timing information for key functions from profiling stats.\n",
    "    \n",
    "    Args:\n",
    "        stats: pstats.Stats object\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with function names and their cumulative times\n",
    "    \"\"\"\n",
    "    # Get all stats\n",
    "    stats_dict = stats.stats\n",
    "    \n",
    "    # Functions we're interested in\n",
    "    ari_functions = [\n",
    "        'adjusted_rand_index',\n",
    "        'get_pair_confusion_matrix', \n",
    "        'get_contingency_matrix'\n",
    "    ]\n",
    "    \n",
    "    partitioning_functions = [\n",
    "        'get_parts',\n",
    "        'run_quantile_clustering',\n",
    "        'get_feature_parts'\n",
    "    ]\n",
    "    \n",
    "    other_functions = [\n",
    "        'cdist_parts_basic',\n",
    "        'compute_ccc',\n",
    "        'compute_coef',\n",
    "        'ccc'\n",
    "    ]\n",
    "    \n",
    "    results = {\n",
    "        'ari': {},\n",
    "        'partitioning': {},\n",
    "        'other': {},\n",
    "        'total_time': 0.0\n",
    "    }\n",
    "    \n",
    "    for key, value in stats_dict.items():\n",
    "        filename, line_num, func_name = key\n",
    "        # value is (ncalls, tottime, cumtime, callers)\n",
    "        ncalls, tottime, cumtime = value[0], value[2], value[3]\n",
    "        \n",
    "        if func_name in ari_functions:\n",
    "            results['ari'][func_name] = {\n",
    "                'ncalls': ncalls,\n",
    "                'tottime': tottime,\n",
    "                'cumtime': cumtime\n",
    "            }\n",
    "        elif func_name in partitioning_functions:\n",
    "            results['partitioning'][func_name] = {\n",
    "                'ncalls': ncalls,\n",
    "                'tottime': tottime,\n",
    "                'cumtime': cumtime\n",
    "            }\n",
    "        elif func_name in other_functions:\n",
    "            results['other'][func_name] = {\n",
    "                'ncalls': ncalls,\n",
    "                'tottime': tottime,\n",
    "                'cumtime': cumtime\n",
    "            }\n",
    "        \n",
    "        # Track total time from the ccc function\n",
    "        if func_name == 'ccc' and 'impl.py' in filename:\n",
    "            results['total_time'] = cumtime\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def calculate_percentages(results: dict) -> dict:\n",
    "    \"\"\"Calculate percentage of total time for each category.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary from extract_function_times\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with percentages\n",
    "    \"\"\"\n",
    "    total = results['total_time']\n",
    "    if total == 0:\n",
    "        return {'ari_pct': 0, 'partitioning_pct': 0, 'other_pct': 0}\n",
    "    \n",
    "    # Sum up tottime (exclusive time) for each category\n",
    "    ari_time = sum(v['tottime'] for v in results['ari'].values())\n",
    "    part_time = sum(v['tottime'] for v in results['partitioning'].values())\n",
    "    \n",
    "    return {\n",
    "        'ari_time': ari_time,\n",
    "        'ari_pct': (ari_time / total) * 100,\n",
    "        'partitioning_time': part_time,\n",
    "        'partitioning_pct': (part_time / total) * 100,\n",
    "        'other_time': total - ari_time - part_time,\n",
    "        'other_pct': ((total - ari_time - part_time) / total) * 100,\n",
    "        'total_time': total\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling Across Different Workload Sizes\n",
    "\n",
    "We test with three representative workload sizes:\n",
    "- **Small**: 10 features x 100 samples (45 pairwise comparisons)\n",
    "- **Medium**: 50 features x 500 samples (1,225 pairwise comparisons)\n",
    "- **Large**: 100 features x 1000 samples (4,950 pairwise comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Profiling Small workload: 1000 features x 1000 samples...\n",
      "  Number of pairwise comparisons: 499500\n",
      "  Total time: 200.1082s\n",
      "  ARI time: 151.2318s (75.6%)\n",
      "  Partitioning time: 0.4323s (0.2%)\n",
      "\n",
      "Profiling Medium workload: 5000 features x 1000 samples...\n",
      "  Number of pairwise comparisons: 12497500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Number of pairwise comparisons: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_pairs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Profile (using single thread to get clean profiling data)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m stats, ccc_result \u001b[38;5;241m=\u001b[39m \u001b[43mprofile_ccc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Extract and analyze results\u001b[39;00m\n\u001b[1;32m     23\u001b[0m func_times \u001b[38;5;241m=\u001b[39m extract_function_times(stats)\n",
      "Cell \u001b[0;32mIn[2], line 29\u001b[0m, in \u001b[0;36mprofile_ccc\u001b[0;34m(data, n_jobs)\u001b[0m\n\u001b[1;32m     26\u001b[0m profiler \u001b[38;5;241m=\u001b[39m cProfile\u001b[38;5;241m.\u001b[39mProfile()\n\u001b[1;32m     27\u001b[0m profiler\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 29\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mccc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m profiler\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Create stats object\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ccc-gpu-benchmark/lib/python3.10/site-packages/ccc/coef/impl.py:878\u001b[0m, in \u001b[0;36mccc\u001b[0;34m(x, y, internal_n_clusters, return_parts, n_chunks_threads_ratio, n_jobs, pvalue_n_perms, partitioning_executor)\u001b[0m\n\u001b[1;32m    863\u001b[0m inputs \u001b[38;5;241m=\u001b[39m get_chunks(n_features_comp, n_workers, n_chunks_threads_ratio)\n\u001b[1;32m    864\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    865\u001b[0m     (\n\u001b[1;32m    866\u001b[0m         i,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m    876\u001b[0m ]\n\u001b[0;32m--> 878\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params, (max_ari_list, max_part_idx_list, pvalues) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    879\u001b[0m     inputs,\n\u001b[1;32m    880\u001b[0m     map_func(compute_coef, inputs),  \u001b[38;5;66;03m# Apply compute_coef to each input\u001b[39;00m\n\u001b[1;32m    881\u001b[0m ):\n\u001b[1;32m    882\u001b[0m     f_idx \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    884\u001b[0m     cm_values[f_idx] \u001b[38;5;241m=\u001b[39m max_ari_list\n",
      "File \u001b[0;32m~/miniconda3/envs/ccc-gpu-benchmark/lib/python3.10/site-packages/ccc/coef/impl.py:509\u001b[0m, in \u001b[0;36mcompute_coef\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# compare all partitions of one object to the all the partitions\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# of the other object, and get the maximium ARI\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m max_ari_list[idx], max_part_idx_list[idx] \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_ccc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobji_parts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjj_parts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcdist_func\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;66;03m# compute p-value if requested\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pvalue_n_perms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m pvalue_n_perms \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# with ThreadPoolExecutor(max_workers=pvalue_n_jobs) as executor_perms:\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m# select the variable that generated more partitions as the one\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;66;03m# to permute\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ccc-gpu-benchmark/lib/python3.10/site-packages/ccc/coef/impl.py:402\u001b[0m, in \u001b[0;36mcompute_ccc\u001b[0;34m(obj_parts_i, obj_parts_j, cdist_func)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_ccc\u001b[39m(obj_parts_i: NDArray, obj_parts_j: NDArray, cdist_func):\n\u001b[1;32m    387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m    Given a set of partitions for two features, it computes the CCC coefficient.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m        of the partitions that maximized the coefficient.\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     comp_values \u001b[38;5;241m=\u001b[39m \u001b[43mcdist_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_parts_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_parts_j\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m     max_flat_idx \u001b[38;5;241m=\u001b[39m comp_values\u001b[38;5;241m.\u001b[39margmax()\n\u001b[1;32m    407\u001b[0m     max_idx \u001b[38;5;241m=\u001b[39m unravel_index_2d(max_flat_idx, comp_values\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/ccc-gpu-benchmark/lib/python3.10/site-packages/ccc/coef/impl.py:266\u001b[0m, in \u001b[0;36mcdist_parts_basic\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y[j, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    264\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m         res[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43mari\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/ccc-gpu-benchmark/lib/python3.10/site-packages/ccc/sklearn/metrics.py:137\u001b[0m, in \u001b[0;36madjusted_rand_index\u001b[0;34m(part0, part1)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madjusted_rand_index\u001b[39m(part0: np\u001b[38;5;241m.\u001b[39mndarray, part1: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    Computes the adjusted Rand index (ARI) between two clustering partitions.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    The code is based on the sklearn implementation here:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        match; it could be negative in some cases) and 1.0 (perfect match).\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     (tn, fp), (fn, tp) \u001b[38;5;241m=\u001b[39m \u001b[43mget_pair_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# convert to Python integer types, to avoid overflow or underflow\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     tn, fp, fn, tp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(tn), \u001b[38;5;28mint\u001b[39m(fp), \u001b[38;5;28mint\u001b[39m(fn), \u001b[38;5;28mint\u001b[39m(tp)\n",
      "File \u001b[0;32m~/miniconda3/envs/ccc-gpu-benchmark/lib/python3.10/site-packages/numba/core/serialize.py:30\u001b[0m, in \u001b[0;36m_numba_unpickle\u001b[0;34m(address, bytedata, hashed)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Keep unpickled object via `numba_unpickle` alive.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m _unpickled_memo \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numba_unpickle\u001b[39m(address, bytedata, hashed):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Used by `numba_unpickle` from _helperlib.c\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m        unpickled object\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     key \u001b[38;5;241m=\u001b[39m (address, hashed)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define workload sizes\n",
    "workloads = [\n",
    "    {'name': 'Small', 'n_features': 1000, 'n_samples': 1000},\n",
    "    {'name': 'Medium', 'n_features': 5000, 'n_samples': 1000},\n",
    "    {'name': 'Large', 'n_features': 10000, 'n_samples': 1000},\n",
    "]\n",
    "\n",
    "# Store results for each workload\n",
    "all_results = []\n",
    "\n",
    "for workload in workloads:\n",
    "    print(f\"\\nProfiling {workload['name']} workload: {workload['n_features']} features x {workload['n_samples']} samples...\")\n",
    "    \n",
    "    # Generate data\n",
    "    data = generate_synthetic_data(workload['n_features'], workload['n_samples'])\n",
    "    n_pairs = (workload['n_features'] * (workload['n_features'] - 1)) // 2\n",
    "    print(f\"  Number of pairwise comparisons: {n_pairs}\")\n",
    "    \n",
    "    # Profile (using single thread to get clean profiling data)\n",
    "    stats, ccc_result = profile_ccc(data, n_jobs=1)\n",
    "    \n",
    "    # Extract and analyze results\n",
    "    func_times = extract_function_times(stats)\n",
    "    percentages = calculate_percentages(func_times)\n",
    "    \n",
    "    # Store results\n",
    "    result = {\n",
    "        'workload': workload['name'],\n",
    "        'n_features': workload['n_features'],\n",
    "        'n_samples': workload['n_samples'],\n",
    "        'n_pairs': n_pairs,\n",
    "        **percentages,\n",
    "        'func_times': func_times\n",
    "    }\n",
    "    all_results.append(result)\n",
    "    \n",
    "    print(f\"  Total time: {percentages['total_time']:.4f}s\")\n",
    "    print(f\"  ARI time: {percentages['ari_time']:.4f}s ({percentages['ari_pct']:.1f}%)\")\n",
    "    print(f\"  Partitioning time: {percentages['partitioning_time']:.4f}s ({percentages['partitioning_pct']:.1f}%)\")\n",
    "\n",
    "print(\"\\nProfiling complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime Breakdown by Workload Size\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Workload</th>\n",
       "      <th>Features</th>\n",
       "      <th>Samples</th>\n",
       "      <th>Pairwise Comparisons</th>\n",
       "      <th>Total Time (s)</th>\n",
       "      <th>ARI Time (s)</th>\n",
       "      <th>ARI %</th>\n",
       "      <th>Partitioning %</th>\n",
       "      <th>Other %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Small</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>65.0%</td>\n",
       "      <td>6.0%</td>\n",
       "      <td>29.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medium</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>1225</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>72.3%</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>25.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Large</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>4950</td>\n",
       "      <td>2.0240</td>\n",
       "      <td>1.4965</td>\n",
       "      <td>73.9%</td>\n",
       "      <td>2.1%</td>\n",
       "      <td>23.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Workload  Features  Samples  Pairwise Comparisons Total Time (s)  \\\n",
       "0    Small        10      100                    45         0.0178   \n",
       "1   Medium        50      500                  1225         0.4724   \n",
       "2    Large       100     1000                  4950         2.0240   \n",
       "\n",
       "  ARI Time (s)  ARI % Partitioning % Other %  \n",
       "0       0.0116  65.0%           6.0%   29.0%  \n",
       "1       0.3415  72.3%           2.0%   25.8%  \n",
       "2       1.4965  73.9%           2.1%   23.9%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create summary DataFrame\n",
    "summary_data = []\n",
    "for r in all_results:\n",
    "    summary_data.append({\n",
    "        'Workload': r['workload'],\n",
    "        'Features': r['n_features'],\n",
    "        'Samples': r['n_samples'],\n",
    "        'Pairwise Comparisons': r['n_pairs'],\n",
    "        'Total Time (s)': f\"{r['total_time']:.4f}\",\n",
    "        'ARI Time (s)': f\"{r['ari_time']:.4f}\",\n",
    "        'ARI %': f\"{r['ari_pct']:.1f}%\",\n",
    "        'Partitioning %': f\"{r['partitioning_pct']:.1f}%\",\n",
    "        'Other %': f\"{r['other_pct']:.1f}%\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"Runtime Breakdown by Workload Size\")\n",
    "print(\"=\" * 80)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Function-Level Breakdown\n",
    "\n",
    "Show the number of calls and time spent in each ARI-related function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed ARI function breakdown for each workload\n",
    "for r in all_results:\n",
    "    print(f\"\\n{r['workload']} Workload - ARI Function Breakdown:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    ari_data = []\n",
    "    for func_name, timing in r['func_times']['ari'].items():\n",
    "        ari_data.append({\n",
    "            'Function': func_name,\n",
    "            'Calls': timing['ncalls'],\n",
    "            'Total Time (s)': f\"{timing['tottime']:.6f}\",\n",
    "            'Cumulative Time (s)': f\"{timing['cumtime']:.6f}\"\n",
    "        })\n",
    "    \n",
    "    if ari_data:\n",
    "        ari_df = pd.DataFrame(ari_data)\n",
    "        display(ari_df)\n",
    "    else:\n",
    "        print(\"  No ARI function data captured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure with subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Colors for categories\n",
    "colors = {'ARI': '#e74c3c', 'Partitioning': '#3498db', 'Other': '#95a5a6'}\n",
    "\n",
    "for idx, r in enumerate(all_results):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Data for pie chart\n",
    "    sizes = [r['ari_pct'], r['partitioning_pct'], r['other_pct']]\n",
    "    labels = ['ARI', 'Partitioning', 'Other']\n",
    "    explode = (0.05, 0, 0)  # Explode ARI slice slightly\n",
    "    \n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        sizes, \n",
    "        explode=explode,\n",
    "        labels=labels,\n",
    "        colors=[colors[l] for l in labels],\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90,\n",
    "        pctdistance=0.6\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"{r['workload']}\\n({r['n_features']}x{r['n_samples']}, {r['n_pairs']} pairs)\")\n",
    "\n",
    "plt.suptitle('CCC Runtime Breakdown by Component', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ccc_runtime_breakdown_pie.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure saved as 'ccc_runtime_breakdown_pie.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked bar chart showing runtime breakdown\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "workload_names = [r['workload'] for r in all_results]\n",
    "ari_pcts = [r['ari_pct'] for r in all_results]\n",
    "part_pcts = [r['partitioning_pct'] for r in all_results]\n",
    "other_pcts = [r['other_pct'] for r in all_results]\n",
    "\n",
    "x = np.arange(len(workload_names))\n",
    "width = 0.6\n",
    "\n",
    "# Create stacked bars\n",
    "bars1 = ax.bar(x, ari_pcts, width, label='ARI Computation', color='#e74c3c')\n",
    "bars2 = ax.bar(x, part_pcts, width, bottom=ari_pcts, label='Partitioning', color='#3498db')\n",
    "bars3 = ax.bar(x, other_pcts, width, bottom=[a+p for a,p in zip(ari_pcts, part_pcts)], \n",
    "               label='Other', color='#95a5a6')\n",
    "\n",
    "# Add labels on bars\n",
    "for i, (a, p, o) in enumerate(zip(ari_pcts, part_pcts, other_pcts)):\n",
    "    ax.text(i, a/2, f'{a:.1f}%', ha='center', va='center', fontweight='bold', color='white')\n",
    "    ax.text(i, a + p/2, f'{p:.1f}%', ha='center', va='center', fontweight='bold', color='white')\n",
    "\n",
    "ax.set_ylabel('Percentage of Total Runtime (%)')\n",
    "ax.set_xlabel('Workload Size')\n",
    "ax.set_title('CCC Runtime Breakdown by Component', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f\"{r['workload']}\\n({r['n_features']}x{r['n_samples']})\" for r in all_results])\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_ylim(0, 105)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ccc_runtime_breakdown_bar.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure saved as 'ccc_runtime_breakdown_bar.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average ARI percentage across all workloads\n",
    "avg_ari_pct = np.mean([r['ari_pct'] for r in all_results])\n",
    "min_ari_pct = min([r['ari_pct'] for r in all_results])\n",
    "max_ari_pct = max([r['ari_pct'] for r in all_results])\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SUMMARY: ARI Computation as CCC Bottleneck\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAcross the tested workloads:\")\n",
    "print(f\"  - Average ARI percentage: {avg_ari_pct:.1f}%\")\n",
    "print(f\"  - Range: {min_ari_pct:.1f}% to {max_ari_pct:.1f}%\")\n",
    "print(f\"\\nThese results demonstrate that ARI computation represents the\")\n",
    "print(f\"dominant computational component of the CCC algorithm, consuming\")\n",
    "print(f\"approximately {avg_ari_pct:.0f}% of the total runtime.\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Analysis: Number of ARI Calls\n",
    "\n",
    "For a dataset with $n$ features and $k$ partitions per feature, CCC performs:\n",
    "- $\\frac{n(n-1)}{2}$ pairwise feature comparisons\n",
    "- For each comparison: $k^2$ ARI calculations (comparing all partition pairs)\n",
    "\n",
    "Total ARI calls: $\\frac{n(n-1)}{2} \\times k^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show number of ARI calls for each workload\n",
    "print(\"Number of ARI Function Calls by Workload:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for r in all_results:\n",
    "    ari_calls = r['func_times']['ari'].get('adjusted_rand_index', {}).get('ncalls', 'N/A')\n",
    "    n_pairs = r['n_pairs']\n",
    "    \n",
    "    print(f\"\\n{r['workload']} ({r['n_features']}x{r['n_samples']}):\")\n",
    "    print(f\"  - Pairwise comparisons: {n_pairs}\")\n",
    "    print(f\"  - ARI function calls: {ari_calls}\")\n",
    "    if isinstance(ari_calls, int):\n",
    "        print(f\"  - Avg ARI calls per comparison: {ari_calls/n_pairs:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix: Full Profiling Output\n",
    "\n",
    "For reference, here is the complete cProfile output for the large workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run profiling for large workload and show full stats\n",
    "print(\"Full cProfile output for Large workload (100x1000):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "data = generate_synthetic_data(100, 1000)\n",
    "stats, _ = profile_ccc(data, n_jobs=1)\n",
    "\n",
    "# Print top 20 functions by cumulative time\n",
    "stats.strip_dirs().sort_stats(SortKey.CUMULATIVE).print_stats(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
